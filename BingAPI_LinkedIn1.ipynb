{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of LinkedIn profiles found:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import http.client, urllib.request, urllib.parse, urllib.error, base64\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "names = pd.read_csv('NameList1.csv')\n",
    "companies = pd.read_csv('CriteriaList1.csv')\n",
    "\n",
    "YOUR_API_KEY = '9fffa2e7b9874dc0be029fe67f7b3cc6'\n",
    "\n",
    "linkedin = []\n",
    "\n",
    "for name, company in zip(names, companies): # zip to loop over names and companies simultaneously\n",
    "    \n",
    "    query = name + company\n",
    "    \n",
    "    try:\n",
    "        headers = {'Ocp-Apim-Subscription-Key': YOUR_API_KEY }\n",
    "        params = urllib.parse.urlencode({'q': query,'count': '5','mkt': 'us-US'}) # returns top 2 (German) results\n",
    "        conn = http.client.HTTPSConnection('api.cognitive.microsoft.com')\n",
    "        conn.request(\"GET\", \"/bing/v7.0/search?%s\" % params, \"{body}\", headers)\n",
    "        response = conn.getresponse()\n",
    "        data = response.read().decode('utf-8')\n",
    "        json_file = json.loads(data)\n",
    "        conn.close()\n",
    "\n",
    "        for result in json_file['webPages']['value']:\n",
    "            title = result['name']\n",
    "            if name.lower() in title.lower(): # checks if the name appears in the title\n",
    "                if 'linkedin.com/in/' in result['displayUrl']: # checks if the search result URL is a LI profile\n",
    "                    linkedin.append([name, company, result['displayUrl']])\n",
    "                    break\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "        \n",
    "# Writing the results to a CSV file\n",
    "with open('linkedin.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in linkedin:\n",
    "        writer.writerow(row)\n",
    "                \n",
    "print('Number of LinkedIn profiles found:')\n",
    "print(len(linkedin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Khary Pryce',\n",
       "  ' Cornell',\n",
       "  'https://www.linkedin.com/in/khary-pryce-54347017a']]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'numpy.ndarray' object has no attribute 'lower'\n",
      "'numpy.ndarray' object has no attribute 'lower'\n",
      "'numpy.ndarray' object has no attribute 'lower'\n",
      "'webPages'\n",
      "'numpy.ndarray' object has no attribute 'lower'\n",
      "'numpy.ndarray' object has no attribute 'lower'\n",
      "Number of LinkedIn profiles found:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import http.client, urllib.request, urllib.parse, urllib.error, base64\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "names = pd.read_csv('NameList2.csv')\n",
    "companies = pd.read_csv('CriteriaList2.csv')\n",
    "names = pd.DataFrame(names).to_numpy()\n",
    "companies = pd.DataFrame(companies).to_numpy()\n",
    "\n",
    "YOUR_API_KEY = '9fffa2e7b9874dc0be029fe67f7b3cc6'\n",
    "\n",
    "linkedin = []\n",
    "\n",
    "for name, company in zip(names, companies): # zip to loop over names and companies simultaneously\n",
    "    \n",
    "    query = name + company\n",
    "    \n",
    "    try:\n",
    "        headers = {'Ocp-Apim-Subscription-Key': YOUR_API_KEY }\n",
    "        params = urllib.parse.urlencode({'q': query,'count': '3','mkt': 'us-US'}) # returns top 2 (German) results\n",
    "        conn = http.client.HTTPSConnection('api.cognitive.microsoft.com')\n",
    "        conn.request(\"GET\", \"/bing/v7.0/search?%s\" % params, \"{body}\", headers)\n",
    "        response = conn.getresponse()\n",
    "        data = response.read().decode('utf-8')\n",
    "        json_file = json.loads(data)\n",
    "        conn.close()\n",
    "\n",
    "        for result in json_file['webPages']['value']:\n",
    "            title = result['name']\n",
    "            if name.lower() in title.lower(): # checks if the name appears in the title\n",
    "                if 'linkedin.com/in/' in result['displayUrl']: # checks if the search result URL is a LI profile\n",
    "                    linkedin.append([name, company, result['displayUrl']])\n",
    "                    break\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "        \n",
    "# Writing the results to a CSV file\n",
    "with open('linkedin.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in linkedin:\n",
    "        writer.writerow(row)\n",
    "                \n",
    "print('Number of LinkedIn profiles found:')\n",
    "print(len(linkedin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Megan Polnet'],\n",
       "       ['Valerie Ho'],\n",
       "       ['Katherine Nguyen'],\n",
       "       ['Khary Pryce'],\n",
       "       ['Maria Adiaconitei'],\n",
       "       ['Ana Elhom']], dtype=object)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types (dtype('<U17'), dtype('<U17')) -> dtype('<U17')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-9b9b36598049>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompany\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompanies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# zip to loop over names and companies simultaneously\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcompany\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types (dtype('<U17'), dtype('<U17')) -> dtype('<U17')"
     ]
    }
   ],
   "source": [
    "import http.client, urllib.request, urllib.parse, urllib.error, base64\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "names = pd.read_csv('NameList2.csv')\n",
    "companies = pd.read_csv('CriteriaList2.csv')\n",
    "names = pd.DataFrame(names).to_numpy(dtype='unicode')\n",
    "companies = pd.DataFrame(companies).to_numpy(dtype='unicode')\n",
    "\n",
    "\n",
    "YOUR_API_KEY = '9fffa2e7b9874dc0be029fe67f7b3cc6'\n",
    "\n",
    "linkedin = []\n",
    "\n",
    "for name, company in zip(names, companies): # zip to loop over names and companies simultaneously\n",
    "    \n",
    "    query = name + company\n",
    "    \n",
    "    try:\n",
    "        headers = {'Ocp-Apim-Subscription-Key': YOUR_API_KEY }\n",
    "        params = urllib.parse.urlencode({'q': query,'count': '3','mkt': 'us-US'}) # returns top 2 (German) results\n",
    "        conn = http.client.HTTPSConnection('api.cognitive.microsoft.com')\n",
    "        conn.request(\"GET\", \"/bing/v7.0/search?%s\" % params, \"{body}\", headers)\n",
    "        response = conn.getresponse()\n",
    "        data = response.read().decode('utf-8')\n",
    "        json_file = json.loads(data)\n",
    "        conn.close()\n",
    "\n",
    "        for result in json_file['webPages']['value']:\n",
    "            title = result['name']\n",
    "            if name.lower() in title.lower(): # checks if the name appears in the title\n",
    "                if 'linkedin.com/in/' in result['displayUrl']: # checks if the search result URL is a LI profile\n",
    "                    linkedin.append([name, company, result['displayUrl']])\n",
    "                    break\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "        \n",
    "# Writing the results to a CSV file\n",
    "with open('linkedin.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in linkedin:\n",
    "        writer.writerow(row)\n",
    "                \n",
    "print('Number of LinkedIn profiles found:')\n",
    "print(len(linkedin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Megan Polnet'],\n",
       "       ['Valerie Ho'],\n",
       "       ['Katherine Nguyen'],\n",
       "       ['Khary Pryce'],\n",
       "       ['Maria Adiaconitei'],\n",
       "       ['Ana Elhom']], dtype='<U17')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_type': 'SearchResponse',\n",
       " 'queryContext': {'originalQuery': \"['Ana Elhom Cornell']\"},\n",
       " 'webPages': {'webSearchUrl': 'https://www.bing.com/search?q=%5b%27Ana+Elhom+Cornell%27%5d',\n",
       "  'totalEstimatedMatches': 1830,\n",
       "  'value': [{'id': 'https://api.cognitive.microsoft.com/api/v7/#WebPages.0',\n",
       "    'name': 'Bullis tennis standout Ana Elhom finds comfort in ...',\n",
       "    'url': 'https://www.washingtonpost.com/news/recruiting-insider/wp/2016/09/20/bullis-tennis-standout-ana-elhom-finds-comfort-in-committing-to-cornell/',\n",
       "    'isFamilyFriendly': True,\n",
       "    'displayUrl': 'https://www.washingtonpost.com/news/recruiting-insider/wp/2016/09/20/bullis-tennis...',\n",
       "    'snippet': 'Bullis tennis standout Ana Elhom finds comfort in committing to Cornell. Bullis senior Ana Elhom, pictured competing at the U.S. Tennis Association National Spring Team Championships in March ...',\n",
       "    'dateLastCrawled': '2020-03-10T00:55:00.0000000Z',\n",
       "    'language': 'en',\n",
       "    'isNavigational': False},\n",
       "   {'id': 'https://api.cognitive.microsoft.com/api/v7/#WebPages.1',\n",
       "    'name': \"Khary Pryce - 2019-20 - Women's Tennis - Cornell ...\",\n",
       "    'url': 'https://cornellbigred.com/sports/womens-tennis/roster/khary-pryce/50452',\n",
       "    'isFamilyFriendly': True,\n",
       "    'displayUrl': 'https://cornellbigred.com/sports/womens-tennis/roster/khary-pryce/50452',\n",
       "    'snippet': '• 2-4 in doubles while competing with Ana Elhom, including advancement into the Round of 32 at the ITA Northeast Region Championships. Prior to Cornell • Competed from the No. 1 position in both singles and doubles for four years at McDonogh School, serving as captain during senior season.',\n",
       "    'dateLastCrawled': '2020-02-25T22:26:00.0000000Z',\n",
       "    'language': 'en',\n",
       "    'isNavigational': False},\n",
       "   {'id': 'https://api.cognitive.microsoft.com/api/v7/#WebPages.2',\n",
       "    'name': 'Colorado Splits against Cornell and Binghamton ...',\n",
       "    'url': 'https://cubuffs.com/news/2019/2/17/tennis-colorado-splits-against-cornell-and-binghamton.aspx',\n",
       "    'isFamilyFriendly': True,\n",
       "    'displayUrl': 'https://cubuffs.com/news/2019/2/17/tennis-colorado-splits-against-cornell-and...',\n",
       "    'snippet': 'In the earlier match against Cornell, Colorado was once again down early without senior Annabelle Andrinopoulos. After Ecton and Nayar defeated Ana Elhom and Katherine Nguyen in the No.2 doubles match by a score of 6-2, the team doubles point rested in the outcome of the No.1 doubles match.',\n",
       "    'dateLastCrawled': '2020-01-25T11:56:00.0000000Z',\n",
       "    'language': 'en',\n",
       "    'isNavigational': False}]},\n",
       " 'rankingResponse': {'mainline': {'items': [{'answerType': 'WebPages',\n",
       "     'resultIndex': 0,\n",
       "     'value': {'id': 'https://api.cognitive.microsoft.com/api/v7/#WebPages.0'}},\n",
       "    {'answerType': 'WebPages',\n",
       "     'resultIndex': 1,\n",
       "     'value': {'id': 'https://api.cognitive.microsoft.com/api/v7/#WebPages.1'}},\n",
       "    {'answerType': 'WebPages',\n",
       "     'resultIndex': 2,\n",
       "     'value': {'id': 'https://api.cognitive.microsoft.com/api/v7/#WebPages.2'}}]}}}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
